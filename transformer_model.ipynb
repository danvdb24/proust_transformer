{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Np_0Ien0LA9"
      },
      "source": [
        "# Transformer model architecture\n",
        "![](https://github.com/PytLab/transformer-from-scratch/blob/master/images/transformer_architecture.png?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jWI2iuaF0LBC"
      },
      "source": [
        "# Transformer implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "paYSBDp_0LBD"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6kCJ_eqE0LBE"
      },
      "source": [
        "## Embed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MCcFAeKU0LBE"
      },
      "source": [
        "### Embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "xAqfXpr30LBF"
      },
      "outputs": [],
      "source": [
        "class Embedder(torch.nn.Module):\n",
        "    \n",
        "    def __init__(self, vocab_size, d_model):\n",
        "        super().__init__()\n",
        "        self.embed = torch.nn.Embedding(vocab_size, d_model)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        # [123, 0, 23, 5] -> [[..512..], [...512...], ...]\n",
        "        return self.embed(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pti1CBHX0LBF"
      },
      "source": [
        "### Positional encoding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yHd1x1AU0LBG"
      },
      "source": [
        "$$ PE_{(pos, 2i)} = sin(pos/10000^{2i/d_{model}}) $$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XY6aClUq0LBG"
      },
      "source": [
        "$$ PE_{(pos, 2i + 1)} = cos(pos/10000^{2i/d_{model}}) $$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "qIVF_HUd0LBH"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "\n",
        "class PositionalEncoder(torch.nn.Module):\n",
        "    \n",
        "    def __init__(self, d_model, max_seq_len=80):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        \n",
        "        # create constant positional encoding matrix\n",
        "        pe_matrix = torch.zeros(max_seq_len, d_model)\n",
        "        \n",
        "        for pos in range(max_seq_len):\n",
        "            for i in range(0, d_model, 2):\n",
        "                pe_matrix[pos, i] = math.sin(pos/10000**(2*i/d_model))\n",
        "                pe_matrix[pos, i+1] = math.cos(pos/10000**(2*i/d_model))\n",
        "        pe_matrix = pe_matrix.unsqueeze(0)     # Add one dimension for batch size\n",
        "        self.register_buffer('pe', pe_matrix)  # Register as persistent buffer\n",
        "        \n",
        "    def forward(self, x):\n",
        "        # x is a sentence after embedding with dim (batch, number of words, vector dimension)\n",
        "        seq_len = x.size()[1]\n",
        "        x = x + self.pe[:, :seq_len]\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ejspsGGR0LBH"
      },
      "source": [
        "## Model layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jW3oTDHd0LBH"
      },
      "source": [
        "### Scaled Dot-Product Attention layer\n",
        "\n",
        "![](https://github.com/PytLab/transformer-from-scratch/blob/master/images/scaled_dot_product_attention.png?raw=1)\n",
        "\n",
        "12*512\n",
        "\n",
        "[512..] x M = k_0\n",
        "[...512] x M = k_1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "GcXGWeFI0LBH"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Given Query, Key, Value, calculate the final weighted value\n",
        "def scaled_dot_product_attention(q, k, v, mask=None, dropout=None):\n",
        "    # Shape of q and k are the same, both are (batch_size, seq_len, d_k)\n",
        "    # Shape of v is (batch_size, seq_len, d_v)\n",
        "    attention_scores = torch.matmul(q, k.transpose(-2, -1))/math.sqrt(q.shape[-1])  # size (batch_size, seq_len, seq_len)\n",
        "    \n",
        "    # Apply mask to scores\n",
        "    # <pad>\n",
        "    if mask is not None:\n",
        "        attention_scores = attention_scores.masked_fill(mask == 0, value=-1e9)\n",
        "        \n",
        "    # Softmax along the last dimension\n",
        "    attention_weights = F.softmax(attention_scores, dim=-1)\n",
        "    \n",
        "    if dropout is not None:\n",
        "        attention_weights = dropout(attention_weights)\n",
        "        \n",
        "    output = torch.matmul(attention_weights, v)\n",
        "    return output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TndN67Dn0LBI"
      },
      "source": [
        "### Multi-Head Attention layer\n",
        "\n",
        "![](https://github.com/PytLab/transformer-from-scratch/blob/master/images/multi_head_attention.png?raw=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "-OU1lPJ10LBI"
      },
      "outputs": [],
      "source": [
        "class MultiHeadAttention(torch.nn.Module):\n",
        "    def __init__(self, n_heads, d_model, dropout=0.1):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.n_heads = n_heads\n",
        "        self.d_model = d_model\n",
        "        self.d_k = self.d_v = d_model//n_heads\n",
        "        \n",
        "        # self attention linear layers\n",
        "        # Linear layers for q, k, v vectors generation in different heads\n",
        "        self.q_linear_layers = []\n",
        "        self.k_linear_layers = []\n",
        "        self.v_linear_layers = []\n",
        "        for i in range(n_heads):\n",
        "            self.q_linear_layers.append(torch.nn.Linear(d_model, self.d_k))\n",
        "            self.k_linear_layers.append(torch.nn.Linear(d_model, self.d_k))\n",
        "            self.v_linear_layers.append(torch.nn.Linear(d_model, self.d_v))\n",
        "        \n",
        "        self.dropout = torch.nn.Dropout(dropout)\n",
        "        self.out = torch.nn.Linear(n_heads*self.d_v, d_model)\n",
        "        \n",
        "    def forward(self, q, k, v, mask=None):\n",
        "        multi_head_attention_outputs = []\n",
        "        for q_linear, k_linear, v_linear in zip(self.q_linear_layers,\n",
        "                                                self.k_linear_layers,\n",
        "                                                self.v_linear_layers):\n",
        "            new_q = q_linear(q)  # size: (batch_size, seq_len, d_k)\n",
        "            new_k = k_linear(k)  # size: (batch_size, seq_len, d_k)\n",
        "            new_v = v_linear(v)  # size: (batch_size, seq_len, d_v)\n",
        "            \n",
        "            # Scaled Dot-Product attention\n",
        "            head_v = scaled_dot_product_attention(new_q, new_k, new_v, mask, self.dropout)  # (batch_size, seq_len, d_v)\n",
        "            multi_head_attention_outputs.append(head_v)\n",
        "            \n",
        "        # Concat\n",
        "        #import pdb; pdb.set_trace()\n",
        "        concat = torch.cat(multi_head_attention_outputs, -1)  # (batch_size, seq_len, n_heads*d_v)\n",
        "        \n",
        "        # Linear layer to recover to original shap\n",
        "        output = self.out(concat)  # (batch_size, seq_len, d_model)\n",
        "        \n",
        "        return output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "djdjfM890LBI"
      },
      "source": [
        "### Feed Forward layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "wNVLcVZ70LBI"
      },
      "outputs": [],
      "source": [
        "class FeedForward(torch.nn.Module):\n",
        "    def __init__(self, d_model, d_ff=2048, dropout=0.1):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.linear_1 = torch.nn.Linear(d_model, d_ff)\n",
        "        self.dropout = torch.nn.Dropout(dropout)\n",
        "        self.linear_2 = torch.nn.Linear(d_ff, d_model)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.dropout(F.relu(self.linear_1(x)))\n",
        "        x = self.linear_2(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ixWQG_zq0LBJ"
      },
      "source": [
        "### Layer Normalization layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kN-S73ls0LBJ"
      },
      "source": [
        "#### Normalization\n",
        "\n",
        "$$\\mu = \\frac{1}{m} \\sum_{i=1}^{m}x_i$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_Mz4_Ry0LBJ"
      },
      "source": [
        "$$\n",
        "\\sigma^{2} = \\frac{1}{m} \\sum^{m}_{i=1}(x_{i} - \\mu)^2\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MvRW7GZ40LBJ"
      },
      "source": [
        "$$\n",
        "\\hat{Z}_i = \\frac{x_i - \\mu_i}{\\sqrt{\\sigma^{2}_{i} + \\epsilon}}\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ibYXTecN0LBK"
      },
      "source": [
        "#### Add two learnable parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QPJMJqDP0LBK"
      },
      "source": [
        "$$\n",
        "\\tilde{Z}_i = \\alpha_i * \\hat{Z}_i + \\beta_i\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "Z-btuLSY0LBK"
      },
      "outputs": [],
      "source": [
        "class LayerNorm(torch.nn.Module):\n",
        "    def __init__(self, d_model, eps=1e-6):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        self.alpha = torch.nn.Parameter(torch.ones(self.d_model))\n",
        "        self.beta = torch.nn.Parameter(torch.zeros(self.d_model))\n",
        "        self.eps = eps\n",
        "        \n",
        "    def forward(self, x):\n",
        "        # x size: (batch_size, seq_len, d_model)\n",
        "        x_hat = (x - x.mean(dim=-1, keepdim=True))/(x.std(dim=-1, keepdim=True) + self.eps)\n",
        "        x_tilde = self.alpha*x_hat + self.beta\n",
        "        return x_tilde"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UUc35mM50LBK"
      },
      "source": [
        "## Encoder & Decoder layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-woxLvJj0LBK"
      },
      "source": [
        "### Encoder layer\n",
        "\n",
        "An encoder layer contains a multi-head attention layer and feed forward layer\n",
        "\n",
        "![](https://github.com/PytLab/transformer-from-scratch/blob/master/images/encoder.png?raw=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "wS-a-5kQ0LBK"
      },
      "outputs": [],
      "source": [
        "class EncoderLayer(torch.nn.Module):\n",
        "    def __init__(self, d_model, n_heads, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        self.norm_1 = LayerNorm(d_model)\n",
        "        self.norm_2 = LayerNorm(d_model)\n",
        "        self.multi_head_attention = MultiHeadAttention(n_heads, d_model)\n",
        "        self.feed_forward = FeedForward(d_model)\n",
        "        self.dropout_1 = torch.nn.Dropout(dropout)\n",
        "        self.dropout_2 = torch.nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, x, mask):\n",
        "        #import pdb; pdb.set_trace()\n",
        "        x = x + self.dropout_1(self.multi_head_attention(x, x, x, mask))\n",
        "        x = self.norm_1(x)\n",
        "        \n",
        "        x = x + self.dropout_2(self.feed_forward(x))\n",
        "        x = self.norm_2(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fgtU7kNv0LBK"
      },
      "source": [
        "### Decoder layer\n",
        "\n",
        "An decoder layer contains two multi-head attention layers and one feed forward layer\n",
        "\n",
        "![](https://github.com/PytLab/transformer-from-scratch/blob/master/images/decoder.png?raw=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "pqHw7jM_0LBL"
      },
      "outputs": [],
      "source": [
        "class DecoderLayer(torch.nn.Module):\n",
        "    def __init__(self, d_model, n_heads, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.norm_1 = LayerNorm(d_model)\n",
        "        self.norm_2 = LayerNorm(d_model)\n",
        "        self.norm_3 = LayerNorm(d_model)\n",
        "        \n",
        "        self.dropout_1 = torch.nn.Dropout(dropout)\n",
        "        self.dropout_2 = torch.nn.Dropout(dropout)\n",
        "        self.dropout_3 = torch.nn.Dropout(dropout)\n",
        "        \n",
        "        self.multi_head_attention_1 = MultiHeadAttention(n_heads, d_model)\n",
        "        self.multi_head_attention_2 = MultiHeadAttention(n_heads, d_model)\n",
        "        \n",
        "        self.feed_forward = FeedForward(d_model)\n",
        "        \n",
        "    def forward(self, x, encoder_output, src_mask, trg_mask):\n",
        "        x = self.dropout_1(self.multi_head_attention_1(x, x, x, trg_mask))\n",
        "        x = x + self.norm_1(x)\n",
        "        \n",
        "        x = self.dropout_2(self.multi_head_attention_2(x, encoder_output, encoder_output, src_mask))\n",
        "        x = x + self.norm_2(x)\n",
        "        \n",
        "        x = self.dropout_3(self.feed_forward(x))\n",
        "        x = x + self.norm_3(x)\n",
        "        \n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "hlaDaiRk0LBL"
      },
      "outputs": [],
      "source": [
        "import copy\n",
        "\n",
        "def clone_layer(module, N):\n",
        "    return torch.nn.ModuleList([copy.deepcopy(module) for i in range(N)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Yh7nvCs0LBL"
      },
      "source": [
        "## Encoder & Decoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "EukdRo420LBL"
      },
      "outputs": [],
      "source": [
        "class Encoder(torch.nn.Module):\n",
        "    def __init__(self, vocab_size, d_model, N, n_heads):\n",
        "        super().__init__()\n",
        "        self.embed = Embedder(vocab_size, d_model)\n",
        "        self.pe = PositionalEncoder(d_model)\n",
        "        self.encoder_layers = clone_layer(EncoderLayer(d_model, n_heads), N)\n",
        "        self.norm = LayerNorm(d_model)\n",
        "        \n",
        "    def forward(self, src, mask):\n",
        "        x = self.embed(src)\n",
        "        x = self.pe(x)\n",
        "        for encoder in self.encoder_layers:\n",
        "            x = encoder(x, mask)\n",
        "        return self.norm(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "5fsr3G700LBL"
      },
      "outputs": [],
      "source": [
        "class Decoder(torch.nn.Module):\n",
        "    def __init__(self, vocab_size, d_model, N, n_heads):\n",
        "        super().__init__()\n",
        "        self.embed = Embedder(vocab_size, d_model)\n",
        "        self.pe = PositionalEncoder(d_model)\n",
        "        self.decoder_layers = clone_layer(DecoderLayer(d_model, n_heads), N)\n",
        "        self.norm = LayerNorm(d_model)\n",
        "        \n",
        "    def forward(self, trg, encoder_output, src_mask, trg_mask):\n",
        "        x = self.embed(trg)\n",
        "        x = self.pe(x)\n",
        "        for decoder in self.decoder_layers:\n",
        "            x = decoder(x, encoder_output, src_mask, trg_mask)\n",
        "        return self.norm(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "menVDSZf0LBL"
      },
      "source": [
        "## Transformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "lqjgewBw0LBL"
      },
      "outputs": [],
      "source": [
        "class Transformer(torch.nn.Module):\n",
        "    def __init__(self, src_vocab_size, trg_vocab_size, d_model, N, n_heads):\n",
        "        super().__init__()\n",
        "        self.encoder = Encoder(src_vocab_size, d_model, N, n_heads)\n",
        "        self.decoder = Decoder(trg_vocab_size, d_model, N, n_heads)\n",
        "        self.linear = torch.nn.Linear(d_model, trg_vocab_size)\n",
        "        \n",
        "    def forward(self, src, trg, src_mask, trg_mask):\n",
        "        encoder_output = self.encoder(src, src_mask)\n",
        "        decoder_output = self.decoder(trg, encoder_output, src_mask, trg_mask)\n",
        "        output = self.linear(decoder_output)\n",
        "        return output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1n2Ipxv30LBM"
      },
      "source": [
        "# Data processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H2ckIjYc0LBM",
        "outputId": "f08a37e6-a88e-4dfc-f0e9-af337ceb0b20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchtext==0.10.0 in /usr/local/lib/python3.7/dist-packages (0.10.0)\n",
            "Requirement already satisfied: torch==1.9.0 in /usr/local/lib/python3.7/dist-packages (from torchtext==0.10.0) (1.9.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext==0.10.0) (4.64.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext==0.10.0) (1.21.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.10.0) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.9.0->torchtext==0.10.0) (4.1.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.10.0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.10.0) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.10.0) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.10.0) (3.0.4)\n"
          ]
        }
      ],
      "source": [
        "import spacy\n",
        "\n",
        "!pip install -U torchtext==0.10.0\n",
        "from torchtext.legacy import data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AkKEN6AR0LBM",
        "outputId": "7255436f-1ec8-458e-f8b1-ac4324a09bcc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Allo', 'la', 'terre']\n"
          ]
        }
      ],
      "source": [
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "tk = nlp.tokenizer(\"I love you so-much!!!\")\n",
        "\n",
        "tokenizer = lambda sentence: [tok.text for tok in nlp.tokenizer(sentence) if tok.text != \" \"]\n",
        "\n",
        "print(tokenizer(\"Allo la terre\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "id": "eiuUBE8v0LBM"
      },
      "outputs": [],
      "source": [
        "SRC = data.Field(lower=True, tokenize=tokenizer)\n",
        "TRG = data.Field(lower=True, tokenize=tokenizer, init_token='<sos>', eos_token='<eos>')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "icnHdRnT0LBM"
      },
      "outputs": [],
      "source": [
        "src_data = open('data/english.txt', 'r')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "Oi2hQQVZ0LBN"
      },
      "outputs": [],
      "source": [
        "trg_data = open('data/french.txt', 'r')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "a8vl2tEv0LBN"
      },
      "outputs": [],
      "source": [
        "raw_data = {'src': [line for line in src_data], 'trg': [line for line in trg_data]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "HiyqQXgi0LBN"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "M-Z-8t6E0LBN"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame(raw_data, columns=['src', 'trg'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "viSVf81N0LBN",
        "outputId": "5c1a8b41-fa85-44c0-d89d-d277b9caffcd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                      src  \\\n",
              "0                                                   Go.\\n   \n",
              "1                                                  Run!\\n   \n",
              "2                                                  Run!\\n   \n",
              "3                                                 Fire!\\n   \n",
              "4                                                 Help!\\n   \n",
              "...                                                   ...   \n",
              "154878  \"Top-down economics never works,\" said Obama. ...   \n",
              "154879  A carbon footprint is the amount of carbon dio...   \n",
              "154880  Death is something that we're often discourage...   \n",
              "154881  Since there are usually multiple websites on a...   \n",
              "154882  If someone who doesn't know your background sa...   \n",
              "\n",
              "                                                      trg  \n",
              "0                                                  Va !\\n  \n",
              "1                                               Cours !\\n  \n",
              "2                                              Courez !\\n  \n",
              "3                                              Au feu !\\n  \n",
              "4                                            À l'aide !\\n  \n",
              "...                                                   ...  \n",
              "154878  « L'économie en partant du haut vers le bas, ç...  \n",
              "154879  Une empreinte carbone est la somme de pollutio...  \n",
              "154880  La mort est une chose qu'on nous décourage sou...  \n",
              "154881  Puisqu'il y a de multiples sites web sur chaqu...  \n",
              "154882  Si quelqu'un qui ne connaît pas vos antécédent...  \n",
              "\n",
              "[154883 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-50a300d6-2549-470c-8f3a-a539177f3847\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>src</th>\n",
              "      <th>trg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Go.\\n</td>\n",
              "      <td>Va !\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Run!\\n</td>\n",
              "      <td>Cours !\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Run!\\n</td>\n",
              "      <td>Courez !\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Fire!\\n</td>\n",
              "      <td>Au feu !\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Help!\\n</td>\n",
              "      <td>À l'aide !\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>154878</th>\n",
              "      <td>\"Top-down economics never works,\" said Obama. ...</td>\n",
              "      <td>« L'économie en partant du haut vers le bas, ç...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>154879</th>\n",
              "      <td>A carbon footprint is the amount of carbon dio...</td>\n",
              "      <td>Une empreinte carbone est la somme de pollutio...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>154880</th>\n",
              "      <td>Death is something that we're often discourage...</td>\n",
              "      <td>La mort est une chose qu'on nous décourage sou...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>154881</th>\n",
              "      <td>Since there are usually multiple websites on a...</td>\n",
              "      <td>Puisqu'il y a de multiples sites web sur chaqu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>154882</th>\n",
              "      <td>If someone who doesn't know your background sa...</td>\n",
              "      <td>Si quelqu'un qui ne connaît pas vos antécédent...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>154883 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-50a300d6-2549-470c-8f3a-a539177f3847')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-50a300d6-2549-470c-8f3a-a539177f3847 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-50a300d6-2549-470c-8f3a-a539177f3847');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "id": "9qg74CpP0LBO"
      },
      "outputs": [],
      "source": [
        "df.to_csv('en_to_fr.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l7QXOZf80LBO",
        "outputId": "af631fde-06bf-4932-9219-bafb6debdf42"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34mdata\u001b[0m/  en_to_fr.csv  \u001b[01;34msample_data\u001b[0m/\n"
          ]
        }
      ],
      "source": [
        "ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "id": "W0jDSvMr0LBO"
      },
      "outputs": [],
      "source": [
        "data_fields = [('src', SRC), ('trg', TRG)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "id": "8aUSLK9n0LBO"
      },
      "outputs": [],
      "source": [
        "train_set = data.TabularDataset('./en_to_fr.csv', format='csv', fields=data_fields)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_set)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kVH6nvS7BD5j",
        "outputId": "eac88275-d747-424f-f053-44cf9ac8092c"
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<torchtext.legacy.data.dataset.TabularDataset object at 0x7fbf15087e10>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wWc_eMf40LBO",
        "outputId": "765b3fe6-b21a-44aa-8fa3-ceb1bc26c5ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<torchtext.legacy.vocab.Vocab object at 0x7fbef6213410>\n"
          ]
        }
      ],
      "source": [
        "SRC.build_vocab(train_set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 179,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZrDEXIXO0LBO",
        "outputId": "cd1c0d48-6714-49e4-da28-d7feca9bd4e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".\n"
          ]
        }
      ],
      "source": [
        "len(SRC.vocab)\n",
        "# print(SRC.vocab.itos[2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {
        "id": "O8BloTMb0LBO"
      },
      "outputs": [],
      "source": [
        "TRG.build_vocab(train_set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jEKKrPrD0LBO",
        "outputId": "06b93b52-edb3-4ad2-b302-de44acdf844c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "26341"
            ]
          },
          "metadata": {},
          "execution_count": 129
        }
      ],
      "source": [
        "len(TRG.vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M2DyTxy_0LBP",
        "outputId": "1ab44dc7-64e8-4da7-eb3e-9c215171601c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torchtext.legacy.data.dataset.TabularDataset at 0x7fbf15087e10>"
            ]
          },
          "metadata": {},
          "execution_count": 130
        }
      ],
      "source": [
        "train_set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aC95XcmB0LBP"
      },
      "source": [
        "# Train transformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {
        "id": "bRE2pDag0LBP"
      },
      "outputs": [],
      "source": [
        "# set some parameters\n",
        "d_model = 512\n",
        "n_heads = 8\n",
        "N = 6\n",
        "src_vocab_size = len(SRC.vocab)\n",
        "trg_vocab_size = len(TRG.vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {
        "id": "lS1lyjv10LBP"
      },
      "outputs": [],
      "source": [
        "model = Transformer(src_vocab_size, trg_vocab_size, d_model, N, n_heads)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F04yyekX0LBP",
        "outputId": "887ff1bc-8501-48c9-9884-16eeb8cff20a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        }
      ],
      "source": [
        "for p in model.parameters():\n",
        "    if p.dim() > 1:\n",
        "        torch.nn.init.xavier_uniform(p)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {
        "id": "HYaXCo0O0LBP"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 184,
      "metadata": {
        "id": "XJcmELY80LBP"
      },
      "outputs": [],
      "source": [
        "train_iter = data.Iterator(train_set, batch_size=1, sort_key=lambda x: (len(x.src), len(x.trg)), shuffle=True, train=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 185,
      "metadata": {
        "id": "mrkQnNHd0LBP"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def create_mask(src_input, trg_input):\n",
        "    # Source input mask\n",
        "    pad = SRC.vocab.stoi['<pad>']\n",
        "    src_mask = (src_input != pad).unsqueeze(1)\n",
        "    \n",
        "    # Target input mask\n",
        "    trg_mask = (trg_input != pad).unsqueeze(1)\n",
        "    \n",
        "    seq_len = trg_input.size(1)\n",
        "    nopeak_mask = np.tril(np.ones((1, seq_len, seq_len)), k=0).astype('uint8')\n",
        "    nopeak_mask = torch.from_numpy(nopeak_mask) != 0\n",
        "    trg_mask = trg_mask & nopeak_mask\n",
        "    \n",
        "    return src_mask, trg_mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 192,
      "metadata": {
        "id": "DL9JSouv0LBP"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "def train_model(n_epochs, output_interval=100):\n",
        "    model.train()\n",
        "    start = time.time()\n",
        "    \n",
        "    for epoch in range(n_epochs):\n",
        "        \n",
        "        total_loss = 0\n",
        "        for i, batch in enumerate(train_iter):\n",
        "            \n",
        "            \n",
        "            src_input = batch.src.transpose(0, 1)  # size (batch_size, seq_len)\n",
        "            trg = batch.trg.transpose(0, 1)  # size (batch_size, seq_len)\n",
        "\n",
        "            \n",
        "            \n",
        "            trg_input = trg[:, :-1]\n",
        "            ys = trg[:, 1:].contiguous().view(-1)\n",
        "\n",
        "            print(\"src input:\")\n",
        "            print(src_input)\n",
        "            print()\n",
        "\n",
        "            print(\"target:\")\n",
        "            print(trg)\n",
        "            print()\n",
        "\n",
        "            print(\"target input:\")\n",
        "            print(trg_input)\n",
        "            print()\n",
        "\n",
        "            print(\"ys:\")\n",
        "            print(ys)\n",
        "            print()\n",
        "            # create src & trg masks\n",
        "            src_mask, trg_mask = create_mask(src_input, trg_input)\n",
        "            preds = model(src_input, trg_input, src_mask, trg_mask)\n",
        "            \n",
        "            optimizer.zero_grad()\n",
        "            loss = F.cross_entropy(preds.view(-1, preds.size(-1)), ys, ignore_index=1)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            total_loss += loss.data\n",
        "\n",
        "            if (i + 1) % output_interval == 0:\n",
        "                avg_loss = total_loss/output_interval\n",
        "                print('time = {}, epoch = {}, iter = {}, loss = {}'.format((time.time() - start)/60,\n",
        "                                                                           epoch + 1,\n",
        "                                                                           i + 1,\n",
        "                                                                           avg_loss))\n",
        "                total_loss = 0\n",
        "                start = time.time()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 194,
      "metadata": {
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "WOKAA7tz0LBQ",
        "outputId": "7e66177c-6d78-477e-8a88-704d8d939336"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src input:\n",
            "tensor([[ 31,  16,   8, 868, 362,   2]])\n",
            "\n",
            "target:\n",
            "tensor([[   2,   34,   27,  253, 2162,    4,    3]])\n",
            "\n",
            "target input:\n",
            "tensor([[   2,   34,   27,  253, 2162,    4]])\n",
            "\n",
            "ys:\n",
            "tensor([  34,   27,  253, 2162,    4,    3])\n",
            "\n",
            "time = 0.02362548510233561, epoch = 1, iter = 1, loss = 8.015908241271973\n",
            "src input:\n",
            "tensor([[318, 153,  11, 141,   7]])\n",
            "\n",
            "target:\n",
            "tensor([[  2, 156, 164,  19,  14, 457,  33,   8,   3]])\n",
            "\n",
            "target input:\n",
            "tensor([[  2, 156, 164,  19,  14, 457,  33,   8]])\n",
            "\n",
            "ys:\n",
            "tensor([156, 164,  19,  14, 457,  33,   8,   3])\n",
            "\n",
            "time = 0.015025500456492107, epoch = 1, iter = 2, loss = 8.71261978149414\n",
            "src input:\n",
            "tensor([[ 30,   4,  86,   8, 758,  56,   7]])\n",
            "\n",
            "target:\n",
            "tensor([[  2,  70,   7,  17, 145,  23, 699,  81,  33,   8,   3]])\n",
            "\n",
            "target input:\n",
            "tensor([[  2,  70,   7,  17, 145,  23, 699,  81,  33,   8]])\n",
            "\n",
            "ys:\n",
            "tensor([ 70,   7,  17, 145,  23, 699,  81,  33,   8,   3])\n",
            "\n",
            "time = 0.01535019079844157, epoch = 1, iter = 3, loss = 8.65533447265625\n",
            "src input:\n",
            "tensor([[ 12,  16,  53,  54,   3,  23,  76, 117,   2]])\n",
            "\n",
            "target:\n",
            "tensor([[  2,  16,  19, 405,   6, 693, 160,  41,   4,   3]])\n",
            "\n",
            "target input:\n",
            "tensor([[  2,  16,  19, 405,   6, 693, 160,  41,   4]])\n",
            "\n",
            "ys:\n",
            "tensor([ 16,  19, 405,   6, 693, 160,  41,   4,   3])\n",
            "\n",
            "time = 0.014833072821299234, epoch = 1, iter = 4, loss = 8.4915132522583\n",
            "src input:\n",
            "tensor([[987,   7]])\n",
            "\n",
            "target:\n",
            "tensor([[   2, 1245,    8,    3]])\n",
            "\n",
            "target input:\n",
            "tensor([[   2, 1245,    8]])\n",
            "\n",
            "ys:\n",
            "tensor([1245,    8,    3])\n",
            "\n",
            "time = 0.01441895564397176, epoch = 1, iter = 5, loss = 7.660421848297119\n",
            "src input:\n",
            "tensor([[  3,  23, 393,  90,  25,   3, 786,   2]])\n",
            "\n",
            "target:\n",
            "tensor([[   2,    5,  922,  595,   93,   18,   11, 9473,    4,    3]])\n",
            "\n",
            "target input:\n",
            "tensor([[   2,    5,  922,  595,   93,   18,   11, 9473,    4]])\n",
            "\n",
            "ys:\n",
            "tensor([   5,  922,  595,   93,   18,   11, 9473,    4,    3])\n",
            "\n",
            "time = 0.015047017733256023, epoch = 1, iter = 6, loss = 8.128800392150879\n",
            "src input:\n",
            "tensor([[   3,   62,  271, 1207,    4,   20,  708,    6,  330,    2]])\n",
            "\n",
            "target:\n",
            "tensor([[    2,  3350,   334,    53,    18,    11,    10, 26161,    15,   345,\n",
            "             4,     3]])\n",
            "\n",
            "target input:\n",
            "tensor([[    2,  3350,   334,    53,    18,    11,    10, 26161,    15,   345,\n",
            "             4]])\n",
            "\n",
            "ys:\n",
            "tensor([ 3350,   334,    53,    18,    11,    10, 26161,    15,   345,     4,\n",
            "            3])\n",
            "\n",
            "time = 0.015655426184336345, epoch = 1, iter = 7, loss = 8.448265075683594\n",
            "src input:\n",
            "tensor([[  3,  49, 499,  15,  52,  84,  75,  48,   2]])\n",
            "\n",
            "target:\n",
            "tensor([[   2,    5,   77,   11,   20,   55,  203, 1506,  694,  110,    4,    3]])\n",
            "\n",
            "target input:\n",
            "tensor([[   2,    5,   77,   11,   20,   55,  203, 1506,  694,  110,    4]])\n",
            "\n",
            "ys:\n",
            "tensor([   5,   77,   11,   20,   55,  203, 1506,  694,  110,    4,    3])\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-194-09835295c489>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_interval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-192-17bba3041601>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(n_epochs, output_interval)\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    147\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    148\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "train_model(3, output_interval=1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PPNJPiF1LSev"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.3"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}